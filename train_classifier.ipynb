{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698d9c29-4161-47e1-b2f0-fbbeb8670bc2",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9626a-01e2-47df-868b-72013681c751",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c319d0-869d-4cd9-b7ff-8bcee45e2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" # or any {'0', '1', '2','3'}\n",
    "from shutil import rmtree\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import applications\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a68df-816c-4e3c-89e6-d82f31dd334b",
   "metadata": {},
   "source": [
    "##  Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d5a9532-2714-4806-8b70-34478f05e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_num_of_classes=30 #not needed\n",
    "v_input_shape=(224, 224, 3)\n",
    "v_path_dataset='../data/sampledataset'\n",
    "v_image_size=(299,299)\n",
    "v_color_mode=\"rgb\" # \"rgb\", \"rgba\", or \"grayscale\"\n",
    "v_batch_size=16 \n",
    "v_epochs = 10\n",
    "\n",
    "v_metrics=['MeanSquaredError','AUC','Precision','Recall','accuracy']\n",
    "v_workspace='./exp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82def82c-374f-47b1-95c1-75c72e158892",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94487fa-1fd5-4bf7-8b07-d02ecfab7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "def load_dataset(root_dataset='../data/sampledataset', image_size=(299,299),color_mode='grayscale', batch_size=16 ):\n",
    "    datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=True,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=True,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        brightness_range=None,\n",
    "        shear_range=0.0,\n",
    "        zoom_range=(0.95,0.95),#####\n",
    "        channel_shift_range=0.0,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.0,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        rescale=1./255,#######\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,# 'channels_last'\n",
    "        validation_split=0.2,\n",
    "        dtype=None,#tf.float32\n",
    "    )\n",
    "\n",
    "    ds_train = datagen.flow_from_directory(\n",
    "        directory=os.path.join (root_dataset),\n",
    "        target_size=image_size,\n",
    "        color_mode=color_mode, #\"rgb\",#grayscale', #\n",
    "        classes=None,# 'sparse' for integer based instead of hot-encode\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=101,\n",
    "        save_to_dir=None,\n",
    "        save_prefix='',\n",
    "        save_format='png',\n",
    "        follow_links=False,\n",
    "        subset='training',\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    ds_validate = datagen.flow_from_directory(\n",
    "        directory=os.path.join (root_dataset),\n",
    "        target_size=image_size,\n",
    "        color_mode=color_mode, #\"rgb\",#grayscale', #\n",
    "        classes=None,# 'sparse' for integer based instead of hot-encode\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=101,\n",
    "        save_to_dir=None,\n",
    "        save_prefix='',\n",
    "        save_format='png',\n",
    "        follow_links=False,\n",
    "        subset='validation',\n",
    "        interpolation='nearest',\n",
    "    )\n",
    "\n",
    "    #class_names=ds_train.class_indices\n",
    "    #print (class_names)\n",
    "    #class_names = list(class_names.keys())\n",
    "    return (ds_train, ds_train.labels),(ds_validate,ds_validate.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf2cc2d-5122-445c-8b08-d773e4a027f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmtree(v_workspace) if os.path.isdir(v_workspace) else None\n",
    "os.mkdir(v_workspace) \n",
    "\n",
    "#os.mkdir(v_workspace) if not(os.path.isdir(v_workspace)) else rmtree(v_workspace)\n",
    "\n",
    "path_csvname = os.path.join(v_workspace,'performance.csv')\n",
    "path_tensorboardLog= os.path.join(v_workspace,'tensorboard.csv')\n",
    "path_checkpoint=os.path.join(v_workspace,'checkpoint')\n",
    "\n",
    "                            \n",
    "CSVLogger_cb = callbacks.CSVLogger(path_csvname,  separator=',',   append=True)\n",
    "\n",
    "\n",
    "TensorBoard_cb = callbacks.TensorBoard(log_dir=path_tensorboardLog,\n",
    "                                          histogram_freq=1,\n",
    "                                          write_graph=True,\n",
    "                                          write_images=True,\n",
    "                                          update_freq=v_batch_size,\n",
    "                                          #write_steps_per_second=False,\n",
    "                                          profile_batch=2,\n",
    "                                          embeddings_metadata=None)\n",
    "\n",
    "\n",
    "ModelCheckpoint_cb = callbacks.ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                                save_best_only=True, ###to save space\n",
    "                                                save_weights_only=False,\n",
    "                                                monitor='val_accuracy',\n",
    "                                                mode='max')\n",
    "\n",
    "\n",
    "EarlyStopping_cb = callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                   min_delta=0.001,\n",
    "                                                   patience=4,\n",
    "                                                   verbose=0, \n",
    "                                                   mode='auto',\n",
    "                                                   baseline=None,\n",
    "                                                   restore_best_weights=False)\n",
    "\n",
    "TerminateOnNaN_cb = callbacks.TerminateOnNaN()\n",
    "\n",
    "ReduceLROnPlateau_cb = callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                            factor=0.01,\n",
    "                                                            patience=3,\n",
    "                                                            verbose=0,\n",
    "                                                            mode='auto',\n",
    "                                                            min_delta=0.001,\n",
    "                                                            cooldown=0,\n",
    "                                                            min_lr=0)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 15:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.0001)\n",
    "\n",
    "LearningRateScheduler_cb = callbacks.LearningRateScheduler(scheduler, \n",
    "                                                                    verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "RemoteMonitor_cb = callbacks.RemoteMonitor(root='http://localhost:9000',\n",
    "                                                    path='/publish/epoch/end/',\n",
    "                                                    field='data',\n",
    "                                                    headers=None,\n",
    "                                                    send_as_json=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc86bae4-ed29-465a-8aa6-5f1635d20ae0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c05e056-f807-428f-b156-88d135e7060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "'''\n",
    "applications.mobilenet_v2.MobileNetV2\n",
    "applications.inception_v3.InceptionV3\n",
    "applications.vgg16.VGG16\n",
    "applications.xception.Xception\n",
    "\n",
    "'''\n",
    "\n",
    "base_model = applications.inception_v3.InceptionV3(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=v_input_shape,\n",
    "    include_top=False) \n",
    "\n",
    "base_model.trainable = False # freeze the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8c8a51-3b3c-4d4d-816b-e3259c0500f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                61470     \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 30)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,864,254\n",
      "Trainable params: 61,470\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a new model on top.\n",
    "inputs = keras.Input(shape=v_input_shape)\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(v_num_of_classes)(x)\n",
    "outputs= keras.layers.Softmax()(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519a708-f87f-49f7-9c4f-1c076ee14638",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08327de7-291d-4ec1-967b-2f5c25b1ca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 680 images belonging to 30 classes.\n",
      "Found 156 images belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_valid, y_valid)=load_dataset(root_dataset=v_path_dataset, \n",
    "                                                    image_size=v_image_size,\n",
    "                                                    color_mode=v_color_mode, \n",
    "                                                    batch_size=v_batch_size )\n",
    "num_of_classes=x_train.num_classes\n",
    "class_indices=x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef930c-2d8d-40d3-8e07-705ee5527e99",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c821e0-de6d-441c-a953-ba875d43ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=v_metrics\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3c7b6-35c3-43ae-b1ee-857b3a87955f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.0863 - mean_squared_error: 0.0306 - auc: 0.7107 - precision: 0.5000 - recall: 0.0029 - accuracy: 0.2044INFO:tensorflow:Assets written to: ./exp/checkpoint/assets\n",
      "43/43 [==============================] - 87s 2s/step - loss: 3.0863 - mean_squared_error: 0.0306 - auc: 0.7107 - precision: 0.5000 - recall: 0.0029 - accuracy: 0.2044 - val_loss: 2.4022 - val_mean_squared_error: 0.0274 - val_auc: 0.8783 - val_precision: 1.0000 - val_recall: 0.0256 - val_accuracy: 0.3526 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.7075 - mean_squared_error: 0.0217 - auc: 0.9558 - precision: 0.9231 - recall: 0.1412 - accuracy: 0.5735INFO:tensorflow:Assets written to: ./exp/checkpoint/assets\n",
      "43/43 [==============================] - 82s 2s/step - loss: 1.7075 - mean_squared_error: 0.0217 - auc: 0.9558 - precision: 0.9231 - recall: 0.1412 - accuracy: 0.5735 - val_loss: 1.9598 - val_mean_squared_error: 0.0238 - val_auc: 0.9205 - val_precision: 0.7826 - val_recall: 0.1154 - val_accuracy: 0.4744 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.1447 - mean_squared_error: 0.0150 - auc: 0.9826 - precision: 0.9680 - recall: 0.4000 - accuracy: 0.7500"
     ]
    }
   ],
   "source": [
    "#Train the top layer\n",
    "callbacksList=[CSVLogger_cb,TensorBoard_cb,ModelCheckpoint_cb,EarlyStopping_cb,TerminateOnNaN_cb,ReduceLROnPlateau_cb,LearningRateScheduler_cb]\n",
    "history=model.fit(x=x_train,\n",
    "                  validation_data=(x_valid),\n",
    "                  batch_size=v_batch_size,\n",
    "                  epochs=v_epochs, \n",
    "                  callbacks=callbacksList,\n",
    "                  shuffle=True\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1034f730-124e-4e21-94c4-df2da389a6eb",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934992c5-7a44-42a9-989c-c69b627faf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join (v_workspace,\"saved_model\")\n",
    "savedModel = os.path.join(v_workspace, \"saved_model\")\n",
    "savedWeights = os.path.join(v_workspace,\"saved_weights\",\"weights\")\n",
    "\n",
    "model.save(savedModel)\n",
    "model.save_weights(savedWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041bf74c-fe74-45c1-921d-0ec807c0313b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
